<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ex_4 Neural Networks Learning]]></title>
    <url>%2FCoursera_ML%2Fex-4%2F</url>
    <content type="text"><![CDATA[Neural NetworksDataset and The initial value数据集依旧是手写数字。定义初始值并引入包：12345678from scipy.io import loadmatimport scipy.optimize as opimport numpy as npinput_layer_size = 400hidden_layer_size = 25num_labels = 10learning_rate = 1 读取数据的方法同ex-3。1234data_mat1 = loadmat('ex4data1.mat')X = np.array(data_mat1['X'])y = np.array(data_mat1['y']) Visualizing the data与ex-3不同，此处参考了github上的代码，发现更为合适。12345678910111213def plot_100_image(X): size = int(np.sqrt(X.shape[1])) sample_idx = np.random.choice(np.arange(X.shape[0]), 100) sample_images = X[sample_idx, :] fig, ax_array = plt.subplots(nrows=10, ncols=10, sharey=True, sharex=True, figsize=(8, 8)) for r in range(10): for c in range(10): ax_array[r, c].matshow((sample_images[10 * r + c].reshape((size, size))).T, cmap=plt.cm.binary) plt.xticks(np.array([])) plt.yticks(np.array([])) &nbsp; Feedforward前向传播的作用就相当于前面Logistic回归和线性回归中的假设函数（Hypothesis），如下图所示。&nbsp; 12345678def feedForward(Theta1, Theta2, X): #(25, 401),(10, 26) m = X.shape[0] a1 = np.c_[np.ones((m,)), X] #(5000, 401) z2 = np.dot(a1, Theta1.T) #(5000, 25) a2 = np.c_[np.ones((m,)), sigmoid(z2)] #(5000, 26) z3 = np.dot(a2, Theta2.T) #(5000, 10) a3 = sigmoid(z3) #(5000, 10) return a1, z2, a2, z3, a3 返回a1, z2, a2, z3, a3是为了获取反向传播算法需要用到的参数。 Cost functionThe cost function for neural networks with regularization is given by$J(\Theta)=\frac{1}{m}\displaystyle\sum^{m}_{i=1}\displaystyle\sum^{K}_{k=1}[-y^{(i)}_klog((h_\theta(x^{(i)}))_k)-(1-y^{(i)}_k)log(1-(h_\theta(x^{(i)}))_k)]+\frac{\lambda}{2m}\displaystyle\sum^{L-1}_{l=1}\displaystyle\sum^{s_l}_{i=1}\displaystyle\sum^{l+1}_{j=1}(\Theta^{(l)}_{i,j})^2$ 1234567891011121314151617def nncostFunction(nn_params, X, y, learning_rate): Theta1 = np.reshape(nn_params[:(input_layer_size + 1)\ * hidden_layer_size], (hidden_layer_size, input_layer_size + 1)) Theta2 = np.reshape(nn_params[(input_layer_size + 1) * \ hidden_layer_size:], (num_labels, hidden_layer_size + 1)) J = 0 m = X.shape[0] a1, z2, a2, z3, a3 = feedForward(Theta1, Theta2, X) for i in range(m): y_i = np.array([1 if label == y[i] else 0 for label in range(11)]) y_i = y_i[1:] #(10, ) J += np.dot(-y_i, np.log(a3[i,:])) - np.dot((1 - y_i), np.log(1 - a3[i,:])) J /= m theta = (np.sum(Theta1[:,1:] * Theta1[:,1:]) + np.sum(Theta2[:,1:] * \ Theta2[:,1:])) * learning_rate / (2 * m) return J + theta BackpropagationSigmoid gradientThe gradient for the sigmoid function can be computed as: $g^{‘}(z)=\frac{d}{dz}g(z)=g(z)(1-g(z))$where $sigmoid(z)=g(z)=\frac{1}{1+e^{-z}}$12345def sigmoid(z): return 1. / (1 + np.exp(-z))def sigmoidGradient(z): return sigmoid(z) * (1 - sigmoid(z)) Random initialization随机生成初始化参数向量（权重）。$\Theta^{(l)}$的范围为$[-\epsilon_{init},\epsilon_{init}]$,此处另$\epsilon_{init}=0.12$。123456def randInitializeWeight(input_layer_size, hidden_layer_size, num_labels): epsilon_init = 0.12 W = np.random.uniform(0, 1, size = (input_layer_size+1) * \ hidden_layer_size +(hidden_layer_size + 1) * num_labels, )\ * 2 * epsilon_init - epsilon_init return W np.random.unifrom(0,1,size)函数是随机生成一个取值为[0,1]的size数组。 Backpropagation我们的最终目的是为了找到$\Theta$来$minJ(\Theta)$，因此我们需要去计算出代价函数$J(\Theta)$和偏导$\frac{\partial}{\partial\Theta^{(l)}_{i,j}}J(\Theta)$，反向传播算法就是为了计算出$\frac{\partial}{\partial\Theta^{(l)}_{i,j}}J(\Theta)$，功能同Logistic回归和线性回归的梯度函数（gradient）。我们另$\delta^{(l)}{j}$为第l层的底j个节点的误差，层数为$L$。$\delta^{(L)}=a^{(L)}-y$ $\delta^{(L-1)}=(\Theta^{(L-1)})^T\delta^{(L)}.*g^{‘}(z^{(L-1)})$ $\delta^{(L-2)}=(\Theta^{(L-2)})^T\delta^{(L-1)}.*g^{‘}(z^{(L-2)})$ …… $\delta^{(2)}=(\Theta^{(2)})^T\delta^{(3)}.*g^{‘}(z^{(2)})$ 注：此处.*为矩阵各个元素对应相乘，且$g^{‘}(z^{(L-1)})=a^{(L-1)}.*(1-a^{(L-1)})$，此处z应是添加了1 伪代码如下：Training Set{$(x^{(1)},y^{(1)}),…,(x^{(m)},y^{(m)})$}Set $\Delta^{(l)}_{i,j}=0$For i=1 to m Set $a^{(1)}=x^{(i)}$ Perform forward propagation to compute $a^{(l)}$ for l=2,3,…,L Using $y^{(i)}$, compute $\delta^{(L)}-y^{(i)}$ Compute$\delta^{(L-1)},\delta^{(L-2)},…,\delta^{(2)}$ $\Delta^{(l)}_{ij}:=\Delta^{(l)}_{ij}+a^{l}_{j}\delta^{(l+1)}_{i}$$D^{(l)}_{ij}:=\frac{1}{m}\Delta^{(l)}_{ij}+\lambda\Theta^{(l)}_{ij}$ if $j\neq0$$D^{(l)}_{ij}:=\frac{1}{m}\Delta^{(l)}_{ij}$ if $j=0$通过数学推导可得：$\frac{\partial}{\partial\Theta^{(l)}_{i,j}}J(\Theta)=D^{(l)}_{ij}$注：此处y需要进行one_hot编码。 1234567891011121314151617181920212223242526272829303132def backpropagation(nn_params, X, y, learning_rate): Theta1 = np.reshape(nn_params[:(input_layer_size + 1)\ * hidden_layer_size], (hidden_layer_size, input_layer_size + 1)) Theta2 = np.reshape(nn_params[(input_layer_size + 1) * \ hidden_layer_size:], (num_labels, hidden_layer_size + 1)) m = X.shape[0] a1, z2, a2, z3, a3 = feedForward(Theta1, Theta2, X) # one_hot one_hot_y = np.array([[1 if y[i] == j else 0 for j in range(11)]for i in range(len(y))]) one_hot_y = one_hot_y[:,1:] delta1 = np.zeros(Theta1.shape) # (25, 401) delta2 = np.zeros(Theta2.shape) # (10, 26) for i in range(m): a1_i = np.reshape(a1[i,:],(1, len(a1[0]))) #(1, 401) z2_i = np.reshape(z2[i,:],(1, len(z2[0]))) #(1, 25) a2_i = np.reshape(a2[i,:],(1, len(a2[0]))) #(1, 26) a3_i = np.reshape(a3[i,:],(1, len(a3[0]))) #(1, 10) y_i = one_hot_y[i, :] d3_i = a3_i - y_i #(1, 10) z2_i = np.c_[np.ones((1,)), z2_i] d2_i = np.dot(Theta2.T, d3_i.T).T * sigmoidGradient(z2_i) #(1, 26) delta1 = delta1 + np.dot(d2_i[:,1:].T,a1_i) delta2 = delta2 + np.dot(d3_i.T, a2_i) delta1 /= m delta2 /= m delta1[:,1:] = delta1[:,1:] + (Theta1[:,1:] * learning_rate) / m delta2[:,1:] = delta2[:,1:] + (Theta2[:,1:] * learning_rate) / m grad = np.concatenate((delta1.flatten(), delta2.flatten())) return grad Learning parameters using minimize12345678def nn_train(X,y): fmin = op.minimize(fun=nncostFunction, x0=nn_params, args=(X, y, learning_rate), method='TNC', jac=backpropagation, options=&#123;'maxiter': 250&#125;) return fminnn_params = randInitializeWeight(input_layer_size, hidden_layer_size, num_labels)print(nn_train(X, y)) 设置最大的迭代次数为250次。结果如下：12345678910 fun: 0.33431033764051943 jac: array([ 1.80122733e-04, 2.91512941e-07, -2.41860480e-07, ..., 7.21952980e-05, 4.92183397e-06, -3.14373459e-05])message: &apos;Max. number of function evaluations reached&apos; nfev: 250 nit: 20 status: 3success: False x: array([-1.10232549e+00, 1.45756471e-03, -1.20930240e-03, ..., -5.52497298e+00, -1.97210589e+00, -1.52716817e+00]) 代价函数为：0.33，这是一个不错的指标。 Predict12345678910111213def get_accuracy(y_pred, y): correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)] accuracy = (sum(correct) / float(len(correct))) print ('accuracy = &#123;0&#125;%'.format(accuracy * 100))theta1 = np.reshape(fmin.x[:(input_layer_size + 1)\ * hidden_layer_size], (hidden_layer_size, input_layer_size + 1))theta2 = np.reshape(fmin.x[(input_layer_size + 1) * \ hidden_layer_size:], (num_labels, hidden_layer_size + 1))a1, z2, a2, z3, a3 = feedForward(theta1, theta2, X)y_pred = np.argmax(a3, axis=1) + 1get_accuracy(y_pred, y) 最后预测的准确率为：accuracy = 99.3%。使用sklearn包来进行评价。12from sklearn.metrics import classification_reportprint(classification_report(y, y_pred)) 结果如下：12345678910111213141516 precision recall f1-score support 1 0.99 0.99 0.99 500 2 0.99 0.99 0.99 500 3 0.99 0.98 0.99 500 4 0.99 0.99 0.99 500 5 0.99 1.00 1.00 500 6 1.00 0.99 1.00 500 7 0.99 0.99 0.99 500 8 0.99 1.00 0.99 500 9 0.99 0.98 0.98 500 10 0.99 1.00 0.99 500 accuracy 0.99 5000 macro avg 0.99 0.99 0.99 5000weighted avg 0.99 0.99 0.99 5000 故已经成功实现基于反向传播的神经网络算法，用于实现手写数字识别。 Visualizing the hidden layer12345678910111213141516def plot_hidden_layer(theta): Theta1 = np.reshape(nn_params[:(input_layer_size + 1)\ * hidden_layer_size], (hidden_layer_size, input_layer_size + 1)) hidden_layer = Theta1[:, 1:] fig, ax_array = plt.subplots(nrows=5, ncols=5, sharey=True, sharex=True, figsize=(5, 5)) for r in range(5): for c in range(5): ax_array[r, c].matshow(hidden_layer[5 * r + c].reshape((20, 20)), cmap=plt.cm.binary) plt.xticks(np.array([])) plt.yticks(np.array([]))plot_hidden_layer(fmin.x)plt.show() &nbsp;]]></content>
      <categories>
        <category>Coursera_ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Coursera_ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex_3 Multi-class Classification and Neural Networks]]></title>
    <url>%2FCoursera_ML%2Fex-3%2F</url>
    <content type="text"><![CDATA[Multi-class Classification以下代码引用如下包：123456import scipyimport scipy.optimize as opfrom scipy.io import loadmatfrom PIL import Imageimport pandas as pd import numpy as np Dataset该数据集是由5000个样本组成的手写数字组成的，并且保存为.mat的Matlab矩阵格式。首先我们需要对数据进行提取，采用scipy.io库中的loadmat函数。12from scipy.io import loadmatdata_mat = loadmat('./ex3data1.mat') 查看其中的关键词：1print(data_mat.keys()) dict_keys([&#39;__header__&#39;, &#39;__version__&#39;, &#39;__globals__&#39;, &#39;X&#39;, &#39;y&#39;])我们选择提取X，y，并将其转化为数组并将y向量化。123X = np.array(pd.DataFrame(data_mat['X']))y = np.array(pd.DataFrame(data_mat['y']))y = y.flatten() 查看X，y的结构1print(X.shape, y.shape) 结果：(5000, 400) (5000,) X：5000个样本，特征有400个，因为每张图片的大小为20*20的灰度图，共有400个像素值。 y：5000个样本，值由1-10组成，其中10代表0（因为Matlab中索引从1开始） Visualizing the data此处的灰度图片，就是由0-255的二维矩阵组成。我们首先随机提取100张图片，将其内容放在一个(2010+pad\11, 20*10+pad*11)的矩阵中（pad为边界），然后通过PIL的Image的fromarray函数将其转化为可输出的图片。1234567891011121314151617181920def displayData(X): pad, row, col = 2, -1, 0 X_shuffle = np.copy(X) np.random.shuffle(X_shuffle) matrix = np.ones((20*10+pad*11,20*10+pad*11)) for i in range (0,100): if i % 10 == 0: row += 1 col = 0 matrix[row*20+(row+1)*pad:(row+1)*20+(row+1)*pad, col*20+(col+1)*pad:(col+1)*20+(col+1)*pad] \ = X_shuffle[i].reshape((20, 20)).T col += 1 else: matrix[row*20+(row+1)*pad:(row+1)*20+(row+1)*pad, col*20+(col+1)*pad:(col+1)*20+(col+1)*pad] \ = X_shuffle[i].reshape((20, 20)).T col += 1 matrix *= 255 picture = Image.fromarray(matrix) picture.show() picture.close() 如下图所示：&nbsp; Vectorizing Logistic RegressionPrepare首先与之前相同，需对特征矩阵进行扩充一列全为1的向量，因为线性模型中含有偏置顶。1X = np.c_[np.ones((len(y), 1)), X] Sigmoid同Logistic Regression。 $g(z)=\frac{1}{1+e^{-z}}$12def sigmoid(z): return 1./(1 + np.exp(-z)) Vectorizing the cost function此处与之前所做的Logistic Regression中的代价函数相同，不在赘述。(不过返回值少了个括号，导致我的准确率一直不对，检查了小半天才看出来，TAT) $J(\theta)=\frac{1}{m}\displaystyle\sum^{m}_{i=1}{[-y^{(i)}log(h_\theta(x^{(i)}))-(1-y^{(i)}log(1-h_\theta(^{(i)}))]}+\frac{\lambda}{2m}\displaystyle\sum^{n}_{j=1}\theta^2_j$12345def cost(theta, X, y, l = 1): h = sigmoid(np.dot(X, theta)) return (-np.dot(y, np.log(h)) - \ np.dot((1-y), np.log(1-h)))/ len(y) + \ l * theta[1:].T.dot(theta[1:]) / (2 * len(y)) Vectorizing the gradient梯度函数也与之前相同。 $\frac{\partial{J(\theta)}}{\partial{\theta_j}}=\frac{1}{m}\displaystyle\sum^{m}_{i=1}(h_\theta(x^{(i)}-y^{(i)})x_j^{(i)}\qquad for\quad j=0$ $\frac{\partial{J(\theta)}}{\partial{\theta_j}}=\frac{1}{m}\displaystyle\sum^{m}_{i=1}(h_\theta(x^{(i)}-y^{(i)})x_j^{(i)}++\frac{\lambda}{m}\theta_j\qquad for\quad j\geq1$123456def gradient(theta, X, y, l = 1): h = sigmoid(np.dot(X, theta)) theta1 = theta * l / len(y) theta1[0] = 0 grad = np.dot(X.T, h - y) / len(y) + theta1 return grad.flatten() One-vs-all Classification在多分类学习中，我们是基于一些基本策略，利用二分类学习器来解决多分类问题。多分类的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解。先对问题进行拆分，然后为拆除的每个二分类任务训练一个分类器；在测试时，对这些分类器的预测结果进行集成以获得最终的分类结果。最经典的拆分策略有三种：”一对一“（One vs. One），”一对其余“（One vs. Rest，亦称One vs. All），“多对多”（Many vs. Many）。OvR（OvA）是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练N个分类器。（以上摘自周志华.《机器学习》）此处我们选择OvA，所以我们需要训练10个分类器，每次把一类作为正例，即正确的数字（标为1），其余作为反例（标为0），将其进行保存。123456789def oneVsAll(X, y, num_labels): all_theta = np.zeros((num_labels, X.shape[1])) for K in range(1, num_labels + 1): initial_theta = np.zeros(X.shape[1],); y_K = np.array([1 if label == K else 0 for label in y]) fmin = op.minimize(fun=cost, x0=initial_theta, args=(X, y_K, 1), method='TNC', jac=gradient) all_theta[K - 1,:] = fmin.x return all_theta 注：关于for循环，我们采用1-10，因为此处以10代表0。 One-vs-all Prediction将所得到的参数矩阵$\theta$与X做矩阵乘法，再用Sigmoid将每个分类的值转化为一个接近0或1的值，最后将10个分类器进行集成，返回每个样本中，值最大的索引，即所预测的数字。（此处+1是因为从零开始，而y是从1开始）1234def preictOneVsAll(all_theta, X): h = sigmoid(X.dot(all_theta.T)) h_argmax = np.argmax(h, axis=1) return h_argmax + 1 最后计算其分类模型的准确率。12345y_pred = preictOneVsAll(all_theta, X)correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]accuracy = (sum(correct) / float(len(correct)))print ('accuracy = &#123;0&#125;%'.format(accuracy * 100)) 注：zip(y_pred, y)是将其转化为一个元组列表，方便计算。准确率为：accuracy = 94.46%，与pdf上结果相近。 Neural NetWorkModel representation神经网络模型：&nbsp; Feedforward Propagation and Prediction12345678910111213141516171819202122232425262728from scipy.io import loadmatimport numpy as npdef sigmoid(z): return 1. / (1 + np.exp(-z))def predict(Theta1, Theta2, X, y): X = np.c_[np.ones(X.shape[0], ), X] hidden = sigmoid(np.dot(X, Theta1.T)) hidden = np.c_[np.ones(hidden.shape[0],), hidden] output = sigmoid(np.dot(hidden, Theta2.T)) y_pred = np.argmax(output, axis=1) + 1 return y_preddata_mat1 = loadmat('./ex3data1.mat')data_mat2 = loadmat('./ex3weights.mat')X = np.matrix(data_mat1['X'])y = np.matrix(data_mat1['y'])Theta1 = np.matrix(data_mat2['Theta1'])Theta2 = np.matrix(data_mat2['Theta2'])y_pred = predict(Theta1, Theta2, X, y)correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]accuracy = sum(correct) / len(correct)print('accuracy=&#123;0&#125;%'.format(accuracy * 100)) 最后预测结果准确率为：97.52%，可见神经网络模型所预测的准确度的确比Logistic回归预测的准确率高，但它容易受过拟合的影响。]]></content>
      <categories>
        <category>Coursera_ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Coursera_ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex_2 Logistic Regression]]></title>
    <url>%2FCoursera_ML%2Fex-2%2F</url>
    <content type="text"><![CDATA[Logistic RegressionVisualizing the dataRead the data采用pandas.read_csv()方法来读取ex2data1.txt文件。123import pandas as pddata = pd.read_csv('ex2data1.txt', names=['exam1', 'exam2', 'admitted']) 12# 查看data的前几项print(data.head()) 123456 exam1 exam2 admitted0 34.623660 78.024693 01 30.286711 43.894998 02 35.847409 72.902198 03 60.182599 86.308552 14 79.032736 75.344376 1 12# 查看data的结构print(data.describe()) 123456789 exam1 exam2 admittedcount 100.000000 100.000000 100.000000mean 65.644274 66.221998 0.600000std 19.458222 18.582783 0.492366min 30.058822 30.603263 0.00000025% 50.919511 48.179205 0.00000050% 67.032988 67.682381 1.00000075% 80.212529 79.360605 1.000000max 99.827858 98.869436 1.000000 Plotting the scatter plot绘制散点图，需将0和1两种情况分开绘制。故需将原数据依照admitted的数据（0/1）将数据进行拆分为positice和negative。 12345678910111213# 绘制散点图import matplotlib.pyplot as pltpositive = data[data.admitted.isin(['1'])]negative = data[data.admitted.isin(['0'])]plt.scatter(positive['exam1'], positive['exam2'], marker='+', c='black', label='Admitted')plt.scatter(negative['exam1'], negative['exam2'], marker='o', c='y', label='Not admitted')plt.legend()plt.show() 散点图如下所示：&nbsp; ImplementationHypothesis and Sigmoidlogistic regression hypothesis is defined as: $h_\theta(x)=g(\theta^Tx)$ The sigmoid function is defined as: $g(z)=\frac{1}{1+e^{-z}}$1234import numpy as np def sigmoid(z): return 1./(1 + np.exp(-z)) Cost function and gradientthe cost function in logistic regression is: $J(\theta)=\frac{1}{m}\displaystyle\sum^{m}_{i=1}{[-y^{(i)}log(h_\theta(x^{(i)}))-(1-y^{(i)}log(1-h_\theta(^{(i)}))]}$ the gradient of the cost is a vector of the same length is defined as follows: $\frac{\partial{J(\theta)}}{\partial{\theta_j}}=\frac{1}{m}\displaystyle\sum^{m}_{i=1}(h_\theta(x^{(i)}-y^{(i)})x_j^{(i)}$123456789def costFunction(theta, X, y): h = sigmoid(np.dot(X, theta)) J = (-np.dot(y,np.log(h)) - np.dot((1 - y),np.log(1-h))) / len(y) return Jdef gradient(theta, X, y): h = sigmoid(np.dot(X, theta)) grad = np.dot(X.T, h - y) / len(y) return grad.flatten() Learning parameters using minimize使用scipy.optimize中的minimize来代替Matlab/Octave中的minunc，去学习找到让costFunction最小的$\theta$。查看op.minimize()方法的信息。12import scipy.optimize as opprint(np.info(op.minimize) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667 minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None, constraints=(), tol=None, callback=None, options=None)Minimization of scalar function of one or more variables.Parameters----------fun : callable The objective function to be minimized. ``fun(x, *args) -&gt; float`` where x is an 1-D array with shape (n,) and `args` is a tuple of the fixed parameters needed to completely specify the function.x0 : ndarray, shape (n,) Initial guess. Array of real elements of size (n,), where &apos;n&apos; is the number of independent variables.args : tuple, optional Extra arguments passed to the objective function and its derivatives (`fun`, `jac` and `hess` functions).method : str or callable, optional Type of solver. Should be one of - &apos;Nelder-Mead&apos; :ref:`(see here) &lt;optimize.minimize-neldermead&gt;` - &apos;Powell&apos; :ref:`(see here) &lt;optimize.minimize-powell&gt;` - &apos;CG&apos; :ref:`(see here) &lt;optimize.minimize-cg&gt;` - &apos;BFGS&apos; :ref:`(see here) &lt;optimize.minimize-bfgs&gt;` - &apos;Newton-CG&apos; :ref:`(see here) &lt;optimize.minimize-newtoncg&gt;` - &apos;L-BFGS-B&apos; :ref:`(see here) &lt;optimize.minimize-lbfgsb&gt;` - &apos;TNC&apos; :ref:`(see here) &lt;optimize.minimize-tnc&gt;` - &apos;COBYLA&apos; :ref:`(see here) &lt;optimize.minimize-cobyla&gt;` - &apos;SLSQP&apos; :ref:`(see here) &lt;optimize.minimize-slsqp&gt;` - &apos;trust-constr&apos;:ref:`(see here) &lt;optimize.minimize-trustconstr&gt;` - &apos;dogleg&apos; :ref:`(see here) &lt;optimize.minimize-dogleg&gt;` - &apos;trust-ncg&apos; :ref:`(see here) &lt;optimize.minimize-trustncg&gt;` - &apos;trust-exact&apos; :ref:`(see here) &lt;optimize.minimize-trustexact&gt;` - &apos;trust-krylov&apos; :ref:`(see here) &lt;optimize.minimize-trustkrylov&gt;` - custom - a callable object (added in version 0.14.0), see below for description. If not given, chosen to be one of ``BFGS``, ``L-BFGS-B``, ``SLSQP``, depending if the problem has constraints or bounds.jac : &#123;callable, &apos;2-point&apos;, &apos;3-point&apos;, &apos;cs&apos;, bool&#125;, optional Method for computing the gradient vector. Only for CG, BFGS, Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov, trust-exact and trust-constr. If it is a callable, it should be a function that returns the gradient vector: ``jac(x, *args) -&gt; array_like, shape (n,)`` where x is an array with shape (n,) and `args` is a tuple with the fixed parameters. Alternatively, the keywords &#123;&apos;2-point&apos;, &apos;3-point&apos;, &apos;cs&apos;&#125; select a finite difference scheme for numerical estimation of the gradient. Options &apos;3-point&apos; and &apos;cs&apos; are available only to &apos;trust-constr&apos;. If `jac` is a Boolean and is True, `fun` is assumed to return the gradient along with the objective function. If False, the gradient will be estimated using &apos;2-point&apos; finite difference estimation.Returns-------res : OptimizeResult The optimization result represented as a ``OptimizeResult`` object. Important attributes are: ``x`` the solution array, ``success`` a Boolean flag indicating if the optimizer exited successfully and ``message`` which describes the cause of the termination. See `OptimizeResult` for a description of other attributes. 通过以上可知： fun：为costFunction，costFunction的参数值theta必须在第一位； x0：为$theta$，即所需要学习的参数值； args：为(X, y)，是一个元组； method：为可选择的方法； jac：为梯度函数 123Result = op.minimize(fun = Fun.costFunction, x0 = theta, args = (X, y), method = 'TNC', jac = Fun.gradient) 最后，所得结果为:12345678 fun: 0.20349770158947492 jac: array([9.32681149e-09, 1.15776343e-07, 4.86078485e-07])message: &apos;Local minimum reached (|pg| ~= 0)&apos; nfev: 36 nit: 17 status: 0success: True x: array([-25.16131854, 0.20623159, 0.20147149]) costFunction的值为0.203，向量$\theta$为x。 Evaluating logistic regressionFor a student with an Exam 1 score of 45 and an Exam 2 score of 851234def predict(X,theta): return sigmoid(theta[0] + theta[1] * X[0] + theta[2] * X[1])print(Fun.predict([45,85],theta)) 所得结果为：0.7762906217710582 Plot the DecisionBoundary123456def plotDecisionBoundary(theta): x = range(30, 100, 10) Y = -(theta[0] + theta[1]*x)/theta[2] plt.plot(x, Y) plt.xlabel('Exam 1 score') plt.ylabel('Exam 2 score') 拟合结果为：&nbsp; Regularized Logistic RegressionVisualizing the dataRead the data采用pandas.read_csv()方法来读取ex2data2.txt文件。123import pandas as pddata = pd.read_csv('ex2data2.txt', names=['test1', 'test2', 'accepted']) Plotting the scatter plot同上12345678910111213141516# 绘制散点图import matplotlib.pyplot as plt positive = data[data.accepted.isin(['1'])]negative = data[data.accepted.isin(['0'])]plt.scatter(positive['test1'], positive['test2'], marker='+', c='black', label='y=1')plt.scatter(negative['test1'], negative['test2'], marker='o', c='y', label='y=0')plt.xlabel('Microchip Test 1')plt.ylabel('Microchip Test 2')plt.legend()plt.show() 散点图如下图所示：&nbsp; Feature mapping拟合这个散点图最好创造一个更高维度假设函数（Hypoththesis），如下图：&nbsp;12345def mapFeature(X): for i in range(2,7): for j in range(0, i + 1): X = np.c_[X, np.power(X[:, 1],i - j)*np.power(X[:, 2], j)] return X 对ex2data2中数据映射为28维度，结果如下：12345678910111213[[ 1.00000000e+00 5.12670000e-02 6.99560000e-01 ... 6.29470940e-04 8.58939846e-03 1.17205992e-01] [ 1.00000000e+00 -9.27420000e-02 6.84940000e-01 ... 1.89305413e-03 -1.39810280e-02 1.03255971e-01] [ 1.00000000e+00 -2.13710000e-01 6.92250000e-01 ... 1.04882142e-02 -3.39734512e-02 1.10046893e-01] ... [ 1.00000000e+00 -4.84450000e-01 9.99270000e-01 ... 2.34007252e-01 -4.82684337e-01 9.95627986e-01] [ 1.00000000e+00 -6.33640000e-03 9.99270000e-01 ... 4.00328554e-05 -6.31330588e-03 9.95627986e-01] [ 1.00000000e+00 6.32650000e-01 -3.06120000e-02 ... 3.51474517e-07 -1.70067777e-08 8.22905998e-10]] Cost function and gradientthe regularized cost function in logistic regression is： $J(\theta)=\frac{1}{m}\displaystyle\sum^{m}_{i=1}{[-y^{(i)}log(h_\theta(x^{(i)}))-(1-y^{(i)}log(1-h_\theta(^{(i)}))]}+\frac{\lambda}{2m}\displaystyle\sum^{n}_{j=1}\theta^2_j$ 我们不需要对$\theta_0$进行正则化。The gradient of the cost function is a vector where the $j^{th}$ element is defined as follows: $\frac{\partial{J(\theta)}}{\partial{\theta_j}}=\frac{1}{m}\displaystyle\sum^{m}_{i=1}(h_\theta(x^{(i)}-y^{(i)})x_j^{(i)}\qquad for\quad j=0$ $\frac{\partial{J(\theta)}}{\partial{\theta_j}}=\frac{1}{m}\displaystyle\sum^{m}_{i=1}(h_\theta(x^{(i)}-y^{(i)})x_j^{(i)}++\frac{\lambda}{m}\theta_j\qquad for\quad j\geq1$ 12345678910111213def costFunctionReg(theta, X, y, l = 1): h = sigmoid(np.dot(X, theta)) J = (-np.dot(y,np.log(h)) - np.dot((1 - y),np.log(1-h))) / len(y) + \ theta[1:].T.dot(theta[1:]) * (l / (2 * len(y))) return Jdef gradientReg(theta, X, y, l = 1): h = sigmoid(np.dot(X, theta)) # 不惩罚第一项 theta1 = theta * l / len(y) theta1[0] = 0 grad = np.dot(X.T, h - y) / len(y) + theta1 return grad.flatten() Learning parameters using minimize同上1234# 此处lambda取1Result = op.minimize(fun = Fun.costFunctionReg, x0 = theta, args = (X, y, 1), method = 'TNC', jac = Fun.gradientReg) 12345678910111213141516171819 fun: 0.5290027299645224 jac: array([-2.15176034e-06, 6.79432526e-07, -3.49220230e-07, 8.75696900e-07, -4.08192926e-08, -9.33913702e-07, -5.14416679e-07, 1.69767803e-08, 1.53043963e-08, -9.72817646e-07, 6.96367745e-08, 3.55014390e-08, -2.79877300e-07, 1.79619883e-07, 2.33072525e-07, 1.47201334e-07, -2.12252965e-07, 6.16789973e-07, -9.25472935e-08, -5.27805873e-08, -1.48180719e-06, 2.31352665e-07, 1.80331319e-07, -1.31371493e-07, -7.18038233e-08, -4.12162550e-07, 1.65946370e-08, -7.35043065e-07])message: &apos;Converged (|f_n-f_(n-1)| ~= 0)&apos; nfev: 32 nit: 7 status: 1success: True x: array([ 1.27271026, 0.62529965, 1.18111686, -2.019874 , -0.91743189, -1.43166928, 0.12393228, -0.36553118, -0.35725405, -0.17516292, -1.45817008, -0.05098418, -0.61558557, -0.27469166, -1.19271298, -0.24217841, -0.20603303, -0.04466177, -0.27778947, -0.29539513, -0.45645982, -1.04319153, 0.02779373, -0.29244865, 0.01555759, -0.32742403, -0.14389149, -0.92467488]) Plotting the decision boundary我们将分类器的预测结果在一个均匀间隔的网格上绘制出非线性决策边界，然后绘制出预测值从y = 0变化到y = 1的等值线图 12345678910def plotDecisionBoundaryReg(theta): x = np.linspace(-1, 1.5, 250) x1, x2 = np.meshgrid(x, x) # x1.ravel()是将其向量化 x3 = np.array([x1.ravel(),x2.ravel()]).T x3 = np.c_[np.ones((len(x3), 1)), x3] z = mapFeature(x3) z = z.dot(theta) z = z.reshape(x1.shape) plt.contour(x1,x2,z,0) $\lambda=1$的拟合结果为：&nbsp;$\lambda=0$的拟合结果为：&nbsp;我们发现$\lambda=0$已经过拟合$\lambda=100$的拟合结果为：&nbsp;我们发现$\lambda=100$已经欠拟合]]></content>
      <categories>
        <category>Coursera_ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Coursera_ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex_1]]></title>
    <url>%2FCoursera_ML%2Fex-1%2F</url>
    <content type="text"><![CDATA[Linear regression with one variablePlotting the DataRead the Data使用pandas库中的read_csv将数据读入。1234import pandas as pddata = pd.read_csv('./ex1data1.txt', names=['Population','Profit']) Plotting the Scatter Plot12345678import matplotlib.pyplot as pltplt.scatter(data['Population'], data['Profit'], marker='x', c='r')plt.xlabel('Population of City in 10,000s')plt.ylabel('Profit in $10,000s')plt.legend()plt.show() 散点图如下所示：&nbsp; Gradient DescentUpdate EquationsThe objective of linear regression is to minimize the cost function $J(\theta)=\frac{1}{2m}\displaystyle\sum^{m}_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2$ where the hypothesis $h_\theta(x)$ is given by the linear model $h_\theta(x)=\theta^Tx=\theta_0+\theta_1x_1$ Recall that the parameters of your model are the $\theta_j$ values. These are the values you will adjust to minimize cost $J(\theta)$. One way to do this is to use the batch gradient descent algorithm. In batch gradient descent, each iteration performs the update $\theta_j:=\theta_j-\alpha\frac{1}{m}\displaystyle\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x^{(i)}_j$ With each step of gradient descent, your parameters $\theta_j$ come closer to the optimal values that will achieve the lowest cost $J(\theta)$. Implementation初始参数为0向量，学习率(learning rate)$\alpha$为0.01，迭代次数为150012345import numpy as nptheta = np.zeros((2,))iterations = 1500alpha = 0.01 Computing the cost $J(\theta)$关于代价函数（cost function），在回归任务中均方误差是是最常用的性能度量，我们试图让均方误差最小化。而基于均方误差最小化来进行模型求解的方法为“最小二乘法”（least square method）。在线性回归中，最小二乘法就是试图找到一条直线，是所有样本到直线上的欧式距离之和最小。1234def computeCost(theta, X, y): h = np.dot(X, theta) # np.sum为向量相加 return np.sum(np.power(h-y,2)) / (2 * len(y)) Gradient descent假设$\alpha=0.01,iterations=1500,$123456789101112131415def gradientDescent(X, y, theta, alpha, num_iters): for iters in range(num_iters): h = np.dot(X, theta) theta -= alpha * np.dot(X.T, (h - y)) / len(y)theta = np.zeros((2,))iterations = 1500alpha = 0.01y = np.array(data.iloc[:,1])X = np.array(data.iloc[:,0])X = np.c_[np.ones((len(y), 1)), X]# gradientDescentgradientDescent(X, y, theta, alpha, iterations) Plotting the linear fit1234def plotLinearPlot(theta): x = range(4,25,2) Y = theta[0] + theta[1]*x plt.plot(x, Y, label='Linear regression') 拟合结果如下：&nbsp; Visualizing $J(\theta)$&nbsp; Linear regression with multiple variablesFeature Normalization因为两个特征的数值相差近1000倍，故我们需要对其进行特征缩放（feature scaling），来加快梯度下降的收敛速度。对于每一个特征值，我们采用:$\frac{x^{(i)}-mean}{std}$, $std$为标准差（standard deviations），来特征缩放。123456def featureNormalize(X): mean = np.ones((len(X), 2)) * np.array([np.mean(X[:, 0]), np.mean(X[:, 1])]) std = np.ones((len(X), 2)) * np.array([np.std(X[:, 0]), np.std(X[:, 1])]) return (X - mean) / std Gradient Descent1234567891011121314151617181920212223import numpy as npcost = []def computeCostMulti(theta, X, y): h = np.dot(X, theta) return np.sum(np.power(h - y, 2)) / (2 * len(y))def gradientDescentMulti(theta, X, y, alpha, num_iters): for iter in range(num_iters): cost.append(computeCostMulti(theta, X, y)) h = np.dot(X, theta) theta -= alpha * np.dot(X.T, h - y) / len(y) return thetaX = np.array([data['size'], data['num']]).TX = X.astype('float')X = featureNormalize(X)X = np.c_[np.ones((len(X), 1)), X]y = np.array(data.iloc[:,2])theta = np.zeros((len(X[0]), ))theta = gradientDescentMulti(theta, X, y, 0.03, 50) Selecting learning rates当$\alpha$=0.3时，cost随迭代次数的变化曲线为：&nbsp;当$\alpha$=0.1时，cost随迭代次数的变化曲线为：&nbsp;当$\alpha$=0.03时，cost随迭代次数的变化曲线为：&nbsp;当$\alpha$=0.01时，cost随迭代次数的变化曲线为：&nbsp;由以上可以得出，$\alpha=0.1$是一个较为合适的学习率。]]></content>
      <categories>
        <category>Coursera_ML</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Coursera_ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine_Learning_week1]]></title>
    <url>%2Fmachine%20learning%2Fweek1%2F</url>
    <content type="text"><![CDATA[机器学习定义【by Tom Mitchell】A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.”一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E后，经过P评判，程序在处理T时的性能有所提升。我认为经验E就是程序上万次的自我练习的经验而任务T就是下棋。性能度量值P呢，就是它在与一 些新的对手比赛时，赢得比赛的概率。 监督学习与无监督学习监督学习（supervised learning）监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成。在房价的例子中，给出一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。监督学习的代表是分类（classification）与回归（regression） 无监督学习（unsupervised learning）输入数据没有被标记，也没有确定的结果。样本数据类别未知，需要根据样本间的相似性对样本集进行分类试图使类内差距最小化，类间差距最大化。通俗点将就是实际应用中，不少情况下无法预先知道样本的标签，也就是说没有训练样本对应的类别，因而只能从原先没有样本标签的样本集开始学习分类器设计。非监督学习目标不是告诉计算机怎么做，而是让它（计算机）自己去学习怎样做事情。无监督学习的代表是聚类（clustering） 线性回归（Linear Regression）]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二元离散型随机变量]]></title>
    <url>%2F%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%2F%E4%BA%8C%E5%85%83%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[二元随机变量定义&nbsp; 二元离散随机变量定义&nbsp; 二元离散随机变量的联合概率分布律定义&nbsp; 联合概率分布律的性质&nbsp; 例&nbsp;&nbsp; 边际分布定义&nbsp;&nbsp; $f(x)$在$x_0$]]></content>
      <categories>
        <category>概率论与数理统计</category>
      </categories>
      <tags>
        <tag>概率论与数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[连续型随机变量]]></title>
    <url>%2F%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%2F%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[分布函数&nbsp; 连续随机变量&nbsp; 概率密度函数的性质&nbsp;&nbsp;&nbsp;&nbsp; 均匀分布定义&nbsp; 均匀分布性质&nbsp; 指数分布定义&nbsp; 指数分布性质&nbsp;&nbsp;&nbsp; 指数分布用途&nbsp; 正态分布定义&nbsp;&nbsp; 用途&nbsp; 标准正态分布&nbsp; 标准正态分布表&nbsp; 标准正态分布性质&nbsp; 正态分布性质&nbsp; 3σ准则&nbsp;]]></content>
      <categories>
        <category>概率论与数理统计</category>
      </categories>
      <tags>
        <tag>概率论与数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[离散型随机变量]]></title>
    <url>%2F%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%2F%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[离散型随机变量定义&nbsp;&nbsp;&nbsp; 0-1分布&nbsp; Bernoulli试验&nbsp;&nbsp; 二项分布&nbsp;&nbsp; 泊松分布&nbsp; 二项分布与泊松分布&nbsp;即当n&gt;10, p&lt;0.1时,二项分布B(n,p)可以用泊松分布π(np)来近似。&nbsp; 几何分布&nbsp;在重复多次的贝努里试验中，试验进行到某种结果出现第一次为止，此时的试验总次数服从几何分布。 如:射击，首次击中目标时射击的次数。]]></content>
      <categories>
        <category>概率论与数理统计</category>
      </categories>
      <tags>
        <tag>概率论与数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[概率论基础]]></title>
    <url>%2F%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%2F%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[频率与概率频率：频率是0~1之间的一个实数，在大量重复试验的基础上给出了随机事件发生可能性的估计。概率：当试验的次数增加时，随机事件A发生的频率的稳定值p称为概率。记为P(A)=p。 条件概率P(B|A)表示A发生的条件下, B发生的条件概率。P(B)!=P(B|A)，其原因在于事件A的发生改变了样本空间。&nbsp;&nbsp; 全概率公式与贝叶斯公式全概率公式&nbsp;&nbsp; 贝叶斯公式&nbsp; 事件独立性定义:设A，B是两随机事件，如果P(AB)=P(A)P(B)，则称A，B相互独立。两两独立并不能推出相互独立 随机变量&nbsp;随机变量分为离散型随机变量和连续性随机变量。]]></content>
      <categories>
        <category>概率论与数理统计</category>
      </categories>
      <tags>
        <tag>概率论与数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写数字分类]]></title>
    <url>%2Fexamples%2F%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[前言MNIST问题可以称作深度学习中的“Hello World”。它与新闻分类一样，也是一个多分类问题。本例采用MNIST数据集，并且使用卷积神经网络模型来解决手写数字识别问题。 正文数据预处理本例采用训练集样本为60000，测试集样本为10000，每张图片大小均为28*28。对训练集、测试集样本转换为4D张量，并将其标准化。对训练集、测试集标签将其向量化。123456789(train_images, train_labels), (test_images, test_labels) = mnist.load_data()train_images = train_images.reshape((60000, 28, 28, 1))train_images = train_images.astype('float32') / 255test_images = test_images.reshape((10000, 28, 28, 1))test_images = test_images.astype('float32') / 255train_labels = to_categorical(train_labels)test_labels = to_categorical(test_labels) 构建网络采用一层卷积层，一层池化层，一层卷积层，一层池化层，一层卷积层，两层全连接层。在最后一层卷积层中，需要对3D数据转化为1D数据。123456789model = models.Sequential()model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))model.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.MaxPooling2D(2, 2))model.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.Flatten())model.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(10, activation='softmax')) 编译模型1234model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) 模型训练1model.fit(train_images, train_labels, epochs=5, batch_size=64) 结果与分析模型在测试集中进行评估，损失度与准确度为：0.027598469233673314 0.9916，比简单的密集连接模型的准确度97.8%要高。 源码123456789101112131415161718192021222324252627282930313233from keras import layersfrom keras import modelsfrom keras.datasets import mnistfrom keras.utils import to_categoricalimport numpy as np (train_images, train_labels), (test_images, test_labels) = mnist.load_data()train_images = train_images.reshape((60000, 28, 28, 1))train_images = train_images.astype('float32') / 255test_images = test_images.reshape((10000, 28, 28, 1))test_images = test_images.astype('float32') / 255train_labels = to_categorical(train_labels)test_labels = to_categorical(test_labels)model = models.Sequential()model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))model.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.MaxPooling2D(2, 2))model.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.Flatten())model.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(10, activation='softmax'))model.compile( optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])model.fit(train_images, train_labels, epochs=5, batch_size=64)test_loss, test_acc = model.evaluate(test_images, test_labels)print(test_loss, test_acc) 后记理解卷积神经网络的基本概念，即特征图、卷积、最大池化。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Keras</tag>
        <tag>Multiclass Classification</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Perceptron]]></title>
    <url>%2Fmachine%20learning%2FPerceptron%2F</url>
    <content type="text"><![CDATA[M-P神经元神经网络中最基本的成分就是神经元（neuron）模型。在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个阈值（threshold），那么它就会被激活，即“兴奋”起来，向其他神经元发送化学物质。M-P神经元就是将上述情形进行抽象所得，如下图。在上述模型中，神经元收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过“激活函数（activation function”）处理以产生神经元的输出。这样把许多这样的神经元按一定的层次结构连接起来，就得到了神经网络。 感知机感知机（Perceptron）是神经网络和支持向量机的基础。 感知机原理感知机是二分类的线性模型，其输入是实例的特征向量，输出的是事例的类别，分别是+1和-1，属于判别模型。假设训练数据集是线性可分的，即存在一个线性超平面能将它们分开，而感知机的学习过程就一定会收敛（converge）而求得适当的权向量w=（w1;w2;…;wn);最后求得一个能够将训练数据集正实例点和负实例点完全正确分开的分离超平面，如下图。如果是非线性可分的数据，感知机学习过程将会发生振荡（fluctuation），w难以稳定下来，不能求得合适解，最后无法获得超平面。 感知机结构它有两层神经元组成，输入层接收外界输入信号传递给输出层，输出层是M-P神经元，如下图 感知机学习过程对于输出，权重wi(i=1,2,…,n)以及阈值θ可通过学习得到。阈值θ可看做一个固定输入为-1.0的“哑结点”所对应的连接权重w(n+1)，这样，权重和阈值的学习就可统一为权重的学习。感知机的学习规则非常简单，对训练样例(x,y)，若当前感知机的输出为，则感知机的权重调整为：其中称为学习率（learning rate）。 感知机解决非线性问题要解决非线性可分问题，需要考虑使用多层功能神经元。如下图则可用两层感知机解决问题。输出层与输入层之间的一层神经元，被称为隐含层（hidden layer），隐含层和输出层神经元都是拥有激活函数的功能神经元 多层前馈神经网络常见的神经网络如下图所示（由两层或两层以上的感知机所组成）。每一层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接，这样的神经网络结构通常称为“多层前馈神经网络”（multi-layer feedforward neural networks），其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行加工，最终结果由输出层神经元输出。神经网络的学习过程，就是根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值，神经网络“学”到的东西，蕴含在连接权与阈值之中。注：“前馈”是指网络拓扑结构上不存在环或回路 参考[1]感知机原理（perceptron）[2]周志华.机器学习.北京：清华大学出版社，2016年]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BackPropagation]]></title>
    <url>%2Fmachine%20learning%2FBackPropagation%2F</url>
    <content type="text"><![CDATA[BP算法简介对于非线性可分问题，需要考虑使用多层功能神经元，因此多层网络的学习能力比单层感知机强得多。而训练多层网络，感知机的学习规则就无法适用了。目前误差逆传播（error BackPropagation）算法是迄今最成功的的神经网络学习算法。BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络，如递归神经网络。 BP算法推导&nbsp;&nbsp;&nbsp; BP算法工作流程1、先将输入实例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果；2、计算输出层的误差，再将误差逆向传播至隐层神经元，最后根据隐层神经元的误差来对连接权和阈值进行调整；3、1,2步骤迭代循环进行，直到达到某些停止条件为止，例如训练误差已达到一个很小的值。 累积BP算法与标准BP算法BP算法的目标是要最小化训练集D上的累积误差但上述推导的是“标准BP算法”：每次仅针对一个训练样例更新连接权和阈值；“累积BP算法”是基于累积误差最小化的算法。 标准BP算法每次更新只针对单个样例，参数更新得非常频繁，，而且对不同样例进行更新得效果可能会出现“抵消”现象。因此，为了达到同样的累积误差极小点，标准BP算法往往需要进行更多次的迭代。 累积BP算法直接针对累积误差最小化，它在读取整个训练集D一遍后才对参数进行更新，其参数更新的频率低得多。但在很多任务中，累积误差下降到一定程度之后，进一步下降会非常缓慢，这时标准BP往往会更快获得较好的解。参考[1]周志华.机器学习.北京：清华大学出版社，2016年]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[预测房价]]></title>
    <url>%2Fexamples%2F%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7%2F</url>
    <content type="text"><![CDATA[前言预测房价是一个回归问题，本例采用20世纪70年代中期波士顿房价数据集（boston_housing)，主要去预测房屋价格的中位数。并已知当时该郊区的一些数据点，如犯罪率、当地房产税率等。这些数据点（特征）都有不同的取值范围。该数据集样本数量较少，只有506个，分为404个训练样本和102个测试样本。 正文数据预处理因为各个特征的取值范围差异很大，如果直接输入，网络会自动适应取值不同的数据，学习效果会很差。所以，我们需要对每个特征进行标准化。标准化：（输入的每个特征-特征平均值）/ 标准差12345678# 数据预处理 标准化mean = train_data.mean(axis=0)train_data -= meanstd = train_data.std(axis=0)train_data /= stdtest_data -= meantest_data /= std 构建网络+编译本例网络采用两个隐藏层，一个输出层；隐藏层：采用Dense（全连接），隐藏单元均为64，激活函数为Relu；输出层：采用Dense，隐藏单元为1，无需激活函数，是一个线性层。这是标量回归（标量回归是预测单一连续值的回归）典型设置。 编译采用：优化器：rmsprop损失函数：MSE（mean squared error）衡量指标：MAE（mean absolute error）1234567def build_model(): model = models.Sequential() model.add(layers.Dense(64,activation='relu',input_shape=(train_data.shape[1],))) model.add(layers.Dense(64,activation='relu')) model.add(layers.Dense(1)) model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) return model 模型训练因为本例的训练集数量过少，所以采用K折交叉验证来进行模型的评估。12345678910111213141516171819202122232425# K折交叉验证k = 4num_val_samples = len(train_data) // knum_epochs = 500all_mae_histories = []for i in range(k): print('processing fold #', i) val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples] val_targets = train_targets[i * num_val_samples : (i + 1) * num_val_samples] partial_train_data = np.concatenate( [train_data[: i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0) partial_train_targets = np.concatenate( [train_targets[:i * num_val_samples], train_targets[( i + 1 ) * num_val_samples:]], axis=0) model = build_model() history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=1,verbose=0) mae_history = history.history['val_mean_absolute_error'] all_mae_histories.append(mae_history) 结果与分析计算所有轮次中的K折验证分数平均值12average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)] （以前从未发现还可以这样用TAT）绘制的验证分数如下：由该图发现，前十个点的取值范围与其他点不同，需删除；纵轴的范围过大，且数据方差也过大，难以看清图的规律，故我们采用指数移动平均值（EMA）来得到光滑的曲线。123456789def smooth_curve(points, factor=0.9): smoothed_points = [] for point in points: if smoothed_points: previous = smoothed_points[-1] smoothed_points.append(previous * factor + point * (1 - factor)) else: smoothed_points.append(point) return smoothed_points 123456smooth_mae_history = smooth_curve(average_mae_history[10:])plt.plot(range(1, len(smooth_mae_history) +1), smooth_mae_history)plt.xlabel('Epochs')plt.ylabel('Validation MAE')plt.show() 再次绘制的验证分数如下：由此发现，在第180轮后，不再显著降低（书上得出的结果和我的不同），之后开始过拟合。因此我们继续调整模型，epochs=180，并在测试集上进行测试，最后MAE为：2.7016119021995393 。在实际价格范围在10000~50000美元，预测房价与实际相差为2700美元左右。 源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970from keras.datasets import boston_housingfrom keras import modelsfrom keras import layersimport numpy as npimport matplotlib.pyplot as plt(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()def build_model(): model = models.Sequential() model.add(layers.Dense(64,activation='relu',input_shape=(train_data.shape[1],))) model.add(layers.Dense(64,activation='relu')) model.add(layers.Dense(1)) model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) return modeldef smooth_curve(points, factor=0.9): smoothed_points = [] for point in points: if smoothed_points: previous = smoothed_points[-1] smoothed_points.append(previous * factor + point * (1 - factor)) else: smoothed_points.append(point) return smoothed_points# 数据预处理 标准化mean = train_data.mean(axis=0)train_data -= meanstd = train_data.std(axis=0)train_data /= stdtest_data -= meantest_data /= std# K折交叉验证k = 4num_val_samples = len(train_data) // knum_epochs = 180all_mae_histories = []for i in range(k): print('processing fold #', i) val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples] val_targets = train_targets[i * num_val_samples : (i + 1) * num_val_samples] partial_train_data = np.concatenate( [train_data[: i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0) partial_train_targets = np.concatenate( [train_targets[:i * num_val_samples], train_targets[( i + 1 ) * num_val_samples:]], axis=0) model = build_model() history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=1,verbose=0) mae_history = history.history['val_mean_absolute_error'] all_mae_histories.append(mae_history)"""average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]smooth_mae_history = smooth_curve(average_mae_history[10:])plt.plot(range(1, len(smooth_mae_history) +1), smooth_mae_history)plt.xlabel('Epochs')plt.ylabel('Validation MAE')plt.show()"""test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)print(test_mae_score) 后记 特征数据范围差异过大时，需要对特征进行标准化或归一化； 回归问题常用的损失函数是均方误差（MSE），常用的回归指标是平均绝对误差（MAE）； 数据过少时，可以采用K折交叉验证； 在绘制图形时，若遇到纵轴范围较大，可以采用指数移动平均值（EMA）来得到光滑的曲线。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Keras</tag>
        <tag>Regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新闻分类]]></title>
    <url>%2Fexamples%2F%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[前言新闻分类是一个多分类问题，本例采用路透社数据集（reuters），该数据集将新闻分为互斥的46个不同的主题，分别有8982个训练样本和2246个测试样本。 正文数据预处理1、数据向量化。仍旧采用one-hot编码。博主发现python的赋值系统居然可以一个列表作为二维矩阵的索引值，直接全体进行赋值，以前从未在Java中感受过。2、标签向量化。因为标签值是一个标量，数据集的多个样本组成了向量。而to_categorical()则可以讲一个向量转化为由0/1组成的二维矩阵。123456789101112131415from keras.utils.np_utils import to_categoricaldef vectorize_sequences(sequences, dimension=10000): results = np.zeros((len(sequences), dimension)) for i, sequence in enumerate(sequences): results[i, sequence] = 1. return results(train_data, train_labels), (test_data, test_labels) = reuters.load_data( num_words=10000)# 数据向量化，转化为2D张量x_train = vectorize_sequences(train_data)x_test = vectorize_sequences(test_data)# 标签向量化y_train = to_categorical(train_labels)y_test = to_categorical(test_labels) 构建网络本例采用两层隐藏层，一层输出层；中间两层均采用Dense（全连接），隐藏单元均为64，激活函数均为Relu；第三层输出层采用Dense，隐藏单元为46（46个新闻分类），激活函数采用softmax。12345# 构建网络model = models.Sequential()model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))model.add(layers.Dense(64,activation='relu'))model.add(layers.Dense(46,activation='softmax')) 编译模型优化器：rmsprop损失函数：categorical_crossentropy（分类交叉熵）衡量指标：accuracy123model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) 模型训练123456789101112# 验证集x_val = x_train[:1000]partial_x_train = x_train[1000:]y_val = y_train[:1000]partial_y_train = y_train[1000:]# 训练模型history = model.fit( partial_x_train, partial_y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val)) 结果与分析训练与验证损失、训练与验证正确率曲线图如下所示：由此可分析，训练在第9轮后达到过拟合。为了降低过拟合，本例采用添加权重正则化、添加dropout正则化,训练轮数设为40。123456789# 构建网络model = models.Sequential()model.add(layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation='relu',input_shape=(10000,)))model.add(layers.Dropout(0.5))model.add(layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation='relu'))model.add(layers.Dropout(0.5))model.add(layers.Dense(46,activation='softmax')) 观察上图，发现过拟合问题得到缓解，在第20轮后出现过拟合，因此将训练轮数设为20。 测试集损失与准确率1results = model.evaluate(x_test, y_test) 损失与准确率：[1.2500886322660099 0.7640249332146037] 预测12predictions = model.predict(x_test)print(np.argmax(predictions[0])) 源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879from keras import modelsfrom keras import layersfrom keras import regularizersfrom keras.datasets import reutersfrom keras.utils.np_utils import to_categoricalimport numpy as npimport matplotlib.pyplot as pltdef vectorize_sequences(sequences, dimension=10000): results = np.zeros((len(sequences), dimension)) for i, sequence in enumerate(sequences): results[i, sequence] = 1. return results(train_data, train_labels), (test_data, test_labels) = reuters.load_data( num_words=10000)# 数据向量化，转化为2D张量x_train = vectorize_sequences(train_data)x_test = vectorize_sequences(test_data)# 标签向量化y_train = to_categorical(train_labels)y_test = to_categorical(test_labels)# 构建网络model = models.Sequential()model.add(layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation='relu',input_shape=(10000,)))model.add(layers.Dropout(0.5))model.add(layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation='relu'))model.add(layers.Dropout(0.5))model.add(layers.Dense(46,activation='softmax'))# 编译模型model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])# 验证集x_val = x_train[:1000]partial_x_train = x_train[1000:]y_val = y_train[:1000]partial_y_train = y_train[1000:]# 训练模型history = model.fit( partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"""# 绘制损失loss = history.history['loss']val_loss = history.history['val_loss']epochs = range(1, len(loss)+1)plt.plot(epochs, loss, 'bo', label='Training loss')plt.plot(epochs, val_loss, 'b', label='Validation loss')plt.title('Training and validation loss')plt.xlabel('Epochs')plt.ylabel('Loss')plt.legend()plt.show()# 绘制精确acc = history.history['acc']val_acc = history.history['val_acc']plt.clf()plt.plot(epochs, acc, 'bo', label='Training acc')plt.plot(epochs, val_acc, 'b', label='Validation acc')plt.xlabel('Epochs')plt.ylabel('Accuracy')plt.legend()plt.show()""""""results = model.evaluate(x_test, y_test)print(results)"""predictions = model.predict(x_test)print(np.argmax(predictions[0])) 后记降低过拟合是整个深度学习的核心问题。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Keras</tag>
        <tag>Multiclass Classification</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电影评论分类]]></title>
    <url>%2Fexamples%2F%E7%94%B5%E5%BD%B1%E8%AF%84%E8%AE%BA%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[前言电影评论分类是一个二分类问题，为了将电影评论区分为正面评论和负面评论。本例采用IMDB数据集，它包含互联网电影数据库（IMDB）的50000条严重两极化评论。数据集被分为用于训练的25000条评论与用于测试的25000条评论。IMDB数据集已经经过预处理：评论（单词序列）已被转换为整数序列，其中每个整数代表字典中的某个单词（按使用频率进行排列）。 正文数据加载本例保留训练数据中前5000个最常出现的单词，低频单词将被舍弃。(因电脑原因，改为5000)12from keras.datasets import imdb(train_data, train_lables), (test_data, test_labels) = imdb.load_data(num_words=5000) 注：实验时，发现数据下载不下来，只能通过本地下载，再将下载后的数据放在 C:\Users\Administrator.keras\datasets文件夹下 数据预处理需要将样本数据的整数序列转换为2D张量。本例采用one-hot编码，将其转换为01的向量。Dense层（全连接层）可以处理浮点数向量数据。12345678import numpy as np def vectorize_sequences(sequences, dimension=5000): results = np.zeros((len(sequences),dimension)) for i, sequence in enumerate(sequences): results[i, sequence] = 1. return resultsx_train = vectorize_sequences(train_data)x_test = vectorize_sequences(test_data) 将标签向量化12y_train = np.asarray(train_lables).astype('float32')y_test = np.asarray(test_lables).astype('float32') 构建网络本例采用：两个中间层（均为全连接层），隐藏单元（hidden unit）个数为16，激活函数为relu（rectified linear unit）；第三层输出一个标量，预测当前情感，激活函数为sigmoid函数；1234567from keras import modelsfrom keras import layersmodel = models.Sequential()model.add(layers.Dense(16, activation='relu', input_shape=(5000,)))model.add(layers.Dense(16,activation='relu'))model.add(layers.Dense(1,activation='sigmoid')) 编译模型本例采用：损失函数：binary_crossentropy(二元交叉熵损失)优化器：rmsprop优化器1234model.compile( optimizer='rmsprop', loss='bianry_crossentropy', metrics=['accuracy']) 训练模型123456789101112x_val = x_train[:10000]partial_x_train = x_train[10000:]y_val = y_train[:10000]partial_y_train = y_train[10000:]history = model.fit( partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val,y_val)) 结果分析绘制训练损失和验证损失123456789101112131415import matplotlib.pyplot as plthistory_dict = history.historyloss_values = history_dict['loss']val_loss_values = history_dict['val_loss']epochs = range(1, len(loss_values) + 1)plt.plot(epochs, loss_values, 'bo', label='Training loss')plt.plot(epochs, val_loss_values, 'b', label='Validation loss')plt.title('Training and validation loss')plt.xlabel('Epochs')plt.ylabel('Loss')plt.legend()plt.show() 绘制训练精度和验证精度12345678910plt.clf()acc = history_dict['acc']val_acc = history_dict['val_acc']plt.plot(epochs, acc, 'bo', label='Training acc')plt.plot(epochs, val_acc, 'b', label='Validation acc')plt.title('Training and validation accuracy')plt.xlabel('Epochs')plt.ylabel('Accuracy')plt.legend()plt.show() 由两图可知，训练损失不断降低，训练精度不断升高。而验证损失却在第4轮达到最低后又继续上升，验证精度在第4轮达到最高后又继续降低。这个原因是因为过拟合，对数据过度优化，导致学到的表示仅适用于训练数据，无法泛化到训练集之外的数据。因此需要在第四轮之后停止训练。123456history = model.fit( partial_x_train, partial_y_train, epochs=4, batch_size=512, validation_data=(x_val,y_val)) 测试集损失与准确率训练轮数在四轮结束后，测试集的损失和准确率结果如下：[0.29896098415374756, 0.87688] 源代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768from keras.datasets import imdbfrom keras import modelsfrom keras import layersimport numpy as npimport matplotlib.pyplot as plt# one-hot编码def vectorize_sequences(sequences, dimension=5000): results = np.zeros((len(sequences), dimension)) for i, sequence in enumerate(sequences): results[i, sequence] = 1. return results(train_data, train_labels), (test_data, test_labels) = imdb.load_data( num_words=5000)# 样本数据转换为2D张量x_train = vectorize_sequences(train_data)x_test = vectorize_sequences(test_data)# 标签向量化y_train = np.asarray(train_labels).astype('float32')y_test = np.asarray(test_labels).astype('float32')x_val = x_train[:10000]partial_x_train = x_train[10000:]y_val = y_train[:10000]partial_y_train = y_train[10000:]# 模型构建model = models.Sequential()model.add(layers.Dense(16, activation='relu', input_shape=(5000,)))model.add(layers.Dense(16,activation='relu'))model.add(layers.Dense(1,activation='sigmoid'))# 编译model.compile(optimizer='rmsprop', loss='binary_crossentropy',metrics=['accuracy'])# 训练history = model.fit(partial_x_train, partial_y_train,epochs=4,batch_size=512,validation_data=(x_val,y_val))history_dict = history.historyloss_values = history_dict['loss']val_loss_values = history_dict['val_loss']epochs = range(1, len(loss_values) + 1)plt.plot(epochs, loss_values, 'bo', label='Training loss')plt.plot(epochs, val_loss_values, 'b', label='Validation loss')plt.title('Training and validation loss')plt.xlabel('Epochs')plt.ylabel('Loss')plt.legend()plt.show()plt.clf()acc = history_dict['acc']val_acc = history_dict['val_acc']plt.plot(epochs, acc, 'bo', label='Training acc')plt.plot(epochs, val_acc, 'b', label='Validation acc')plt.title('Training and validation accuracy')plt.xlabel('Epochs')plt.ylabel('Accuracy')plt.legend()plt.show()## 预测results = model.evaluate(x_test, y_test)print(results) 后记可以通过降低过拟合来进一步优化，提高预测精度]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Binary Classification</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
</search>
